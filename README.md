# Unimplicit

Python scripts and R code for the paper '_Pre-trained Language Models' Interpretation of Evaluativity Implicature: Evidence from Gradable Adjectives Usage in Context_' Unimplicit workshop @ NAACL-2022

## Citation
```tex
@inproceedings{cong2022pre,
  title={Pre-trained Language Modelsâ€™ Interpretation of Evaluativity Implicature: Evidence from Gradable Adjectives Usage in Context},
  author={Cong, Yan},
  booktitle={Proceedings of the Second Workshop on Understanding Implicit and Underspecified Language},
  pages={1--7},
  year={2022}
}
```
